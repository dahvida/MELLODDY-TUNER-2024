{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e00546",
   "metadata": {},
   "source": [
    "### Import relevant matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "t2 = pd.read_csv('/path/to/T2.csv')\n",
    "t5 = pd.read_csv('/path/to/T5.csv')\n",
    "t6_cont = pd.read_csv('/path/to/T6_cont.csv')\n",
    "x = sparse.load_npz('/path/to/cls_T11_x.npz')\n",
    "x = x.toarray()\n",
    "y = sparse.load_npz('/path/to/cls_T10_y.npz')\n",
    "y = y.toarray()\n",
    "folds = np.load('/path/to/cls_T11_fold_vector.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01605794",
   "metadata": {},
   "source": [
    "Check that t6_cont and the X, y and fold vectors match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(folds) == len(t6_cont) == len(x) == len(y)\n",
    "assert np.sum(np.abs(t6_cont.fold_id.astype(float).to_numpy() - folds)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688e6ae",
   "metadata": {},
   "source": [
    "### Define lookup function to map from X and Y arrays back to SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9134a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(idx, t6_cont, t5, t2):\n",
    "    \"\"\"\n",
    "    Lookup function to go from arrays generated via MELLODDY-Tuner back to input SMILES.\n",
    "    \n",
    "    Path goes like this:\n",
    "    T6_cont (descriptor vector ID) -> T5 (descriptor vector ID, input compound ID) -> T2 (input compound ID, SMILES)\n",
    "\n",
    "    T6_cont already includes some preprocessing like dropping compounds with no measurements, or the ones that\n",
    "    failed standardization. \n",
    "    Crucially, it is also post-aggregation, meaning, it can be that for a given descriptor vector ID, \n",
    "    multiple compound IDs can be found. In that case, we pick the first (they should be all extremely \n",
    "    similar if they got the same ECFP/RDKIT/...)\n",
    "    \"\"\"\n",
    "    map_1 = t6_cont.iloc[idx]['descriptor_vector_id']\n",
    "    map_2 = t5.loc[t5.descriptor_vector_id == map_1]['input_compound_id'].iloc[0]\n",
    "    map_3 = t2.loc[t2.input_compound_id == map_2][\"smiles\"].iloc[0]\n",
    "\n",
    "    return map_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce3109",
   "metadata": {},
   "source": [
    "### Get all SMILES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "smi = []\n",
    "for i in tqdm(range(len(t6_cont)), desc=\"Processing\"):\n",
    "    smi.append(lookup(i, t6_cont, t5, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea230ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(smi) == len(x) == len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e70723",
   "metadata": {},
   "source": [
    "Run a few tests to see if descriptors indeed match the output of MELLODDY-Tuner (Careful: this only works if you point to the RDKIT output in the first cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "import random\n",
    "rdkit_all_descriptors = [x[0] for x in Descriptors._descList]\n",
    "calc = MolecularDescriptorCalculator(rdkit_all_descriptors)\n",
    "\n",
    "n_tests = 500           # edit this if you want to test more\n",
    "\n",
    "random_indices = random.sample(range(len(smi)), n_tests)\n",
    "\n",
    "mae = []\n",
    "for i in random_indices:\n",
    "    mol = Chem.MolFromSmiles(smi[i])\n",
    "    out = calc.CalcDescriptors(mol)\n",
    "    mae.append(np.mean(np.abs(x[i] - out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92802b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.median(mae) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2990d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(mae, bins = 20)\n",
    "plt.xlabel(\"MAE between lookup and MELLODDY-Tuner\")\n",
    "plt.title(\"MAE distribution\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158ee24",
   "metadata": {},
   "source": [
    "### Format as a Dataframe for Chemprop CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemprop needs a SMILES column first, then all the others are labels\n",
    "colnames = [f\"MELLODDY_{x}\" for x in range(y.shape[1])]\n",
    "df = pd.DataFrame(data=y,\n",
    "                  columns=colnames)\n",
    "df[\"SMILES\"] = smi\n",
    "new_col_order = [\"SMILES\"] + colnames\n",
    "df = df[new_col_order]\n",
    "\n",
    "# Labels should be either 0 or 1, with NaN for missing values\n",
    "# In sparsechem, negative labels instead are -1 and missing labels are 0\n",
    "df = df.replace(0, np.nan)\n",
    "df = df.replace(-1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e489f",
   "metadata": {},
   "source": [
    "### Create train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7a56ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 0\n",
    "\n",
    "df[\"FOLD_ID\"] = t6_cont.fold_id\n",
    "test_set = df[df[\"FOLD_ID\"] == test_id]\n",
    "train_set = df[df[\"FOLD_ID\"] != test_id]\n",
    "train_set = train_set.drop(\"FOLD_ID\", axis=1)\n",
    "test_set = test_set.drop(\"FOLD_ID\", axis=1)\n",
    "\n",
    "print(f\"Length of the training set: {len(train_set)}\")\n",
    "print(f\"Length of the test set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e2d7f5",
   "metadata": {},
   "source": [
    "### Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('/path/to/train_set.csv')\n",
    "test_set.to_csv('/path/to/train_set.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
